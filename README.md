# CV Processor - Sistema de AnÃ¡lisis AutomÃ¡tico de CVs con IA

Sistema inteligente para el anÃ¡lisis automÃ¡tico de currÃ­culums vitae utilizando inteligencia artificial local (Ollama + DeepSeek-R1) con aceleraciÃ³n GPU NVIDIA. El sistema procesa archivos PDF, extrae informaciÃ³n relevante y proporciona anÃ¡lisis detallados de candidatos.

## ğŸŒŸ CaracterÃ­sticas Principales

- **AnÃ¡lisis de CV con IA**: Utiliza DeepSeek-R1 para anÃ¡lisis inteligente y preciso
- **Interfaz Web**: Interfaz moderna para gestiÃ³n de archivos y visualizaciÃ³n de resultados
- **API REST**: Endpoints completos para integraciÃ³n con otros sistemas
- **AceleraciÃ³n GPU**: Optimizado para GPUs NVIDIA con CUDA
- **Procesamiento PDF**: ExtracciÃ³n de texto avanzada con correcciÃ³n de caracteres
- **Base de Datos SQLite**: Almacenamiento persistente de candidatos y anÃ¡lisis
- **GestiÃ³n de Archivos**: Upload, listado y eliminaciÃ³n de CVs

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â–¶â”‚   FastAPI        â”‚â”€â”€â”€â–¶â”‚   Ollama        â”‚
â”‚   (HTML/JS/CSS) â”‚    â”‚   REST API       â”‚    â”‚   + DeepSeek-R1 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                          â”‚
                              â–¼                          â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   SQLite     â”‚           â”‚   GPU       â”‚
                       â”‚   Database   â”‚           â”‚   NVIDIA    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requisitos del Sistema

### Hardware
- **GPU**: NVIDIA GTX 1050 o superior (mÃ­nimo 4GB VRAM)
- **RAM**: 8GB mÃ­nimo, 16GB recomendado
- **Almacenamiento**: 10GB libres para modelos de IA

### Software
- **OS**: Linux (Ubuntu 20.04+ recomendado)
- **Python**: 3.8+
- **NVIDIA Drivers**: 535.x o superior
- **CUDA**: 12.x
- **Ollama**: Ãšltima versiÃ³n

---

# ğŸš€ DocumentaciÃ³n instalar drivers de Nvidia para usar CUDA en linux

## 1. Verificar la tarjeta grÃ¡fica NVIDIA

```bash
# Verificar que tienes una GPU NVIDIA
lspci | grep -i nvidia

# Verificar el modelo especÃ­fico
nvidia-smi

```

## 2. Instalar drivers NVIDIA

```bash
# Actualizar el sistema
sudo apt update && sudo apt upgrade -y

# Instalar drivers recomendados
sudo ubuntu-drivers devices
sudo ubuntu-drivers autoinstall

# O instalar manualmente (reemplaza XXX con la versiÃ³n)
sudo apt install nvidia-driver-535

# Reiniciar el sistema
sudo reboot

```

## 3. Verificar instalaciÃ³n de drivers

```bash
# Verificar que los drivers estÃ¡n funcionando
nvidia-smi

# DeberÃ­a mostrar informaciÃ³n de tu GPU

```

## 4. Instalar CUDA Toolkit

```bash
# Descargar e instalar CUDA (versiÃ³n 12.x)
wget https://developer.download.nvidia.com/compute/cuda/12.3.0/local_installers/cuda_12.3.0_545.23.06_linux.run

# Hacer ejecutable
chmod +x cuda_12.3.0_545.23.06_linux.run

# Instalar (NO instalar drivers si ya estÃ¡n instalados)
sudo sh cuda_12.3.0_545.23.06_linux.run

```

## 5. Configurar variables de entorno

```bash
# Editar .bashrc
nano ~/.bashrc

# Agregar al final del archivo:
export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

# Recargar configuraciÃ³n
source ~/.bashrc

```

## 6. Verificar instalaciÃ³n de CUDA

```bash
# Verificar versiÃ³n de CUDA
nvcc --version

# Verificar que las librerÃ­as estÃ¡n disponibles
nvidia-smi

```

## 7. Instalar Ollama

```bash
# MÃ©todo 1: Script oficial
curl -fsSL https://ollama.ai/install.sh | sh

# MÃ©todo 2: Manual
wget https://github.com/ollama/ollama/releases/latest/download/ollama-linux-amd64
sudo mv ollama-linux-amd64 /usr/local/bin/ollama
sudo chmod +x /usr/local/bin/ollama

```

## 8. Configurar Ollama para usar GPU

```bash
# Iniciar servicio Ollama
sudo systemctl start ollama
sudo systemctl enable ollama

# O ejecutar manualmente
ollama serve &

```

## 9. Verificar que Ollama detecta CUDA

```bash
# Verificar informaciÃ³n del sistema
ollama --version

# Descargar un modelo para probar
ollama pull llama2

# Ejecutar modelo (deberÃ­a usar GPU automÃ¡ticamente)
ollama run llama2

```

## 10. Comandos de diagnÃ³stico

```bash
# Verificar uso de GPU mientras ejecutas Ollama
watch -n 1 nvidia-smi

# Verificar logs de Ollama
journalctl -u ollama -f

# Verificar procesos usando GPU
nvidia-smi pmon

# Verificar librerÃ­as CUDA
ldconfig -p | grep cuda

```

## 11. SoluciÃ³n de problemas comunes

### Si Ollama no detecta CUDA:

```bash
# Verificar que CUDA estÃ¡ en el PATH
echo $PATH
echo $LD_LIBRARY_PATH

# Reinstalar Ollama con soporte CUDA explÃ­cito
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar compatibilidad de versiones
nvidia-smi
nvcc --version

```

### Si hay conflictos de drivers:

```bash
# Limpiar instalaciones previas
sudo apt remove --purge nvidia-*
sudo apt autoremove
sudo apt autoclean

# Reinstalar drivers
sudo ubuntu-drivers autoinstall
sudo reboot

```

### Variables de entorno adicionales:

```bash
# Si persisten problemas, agregar a ~/.bashrc:
export CUDA_HOME=/usr/local/cuda
export CUDA_ROOT=/usr/local/cuda
export NVIDIA_VISIBLE_DEVICES=all
export NVIDIA_DRIVER_CAPABILITIES=compute,utility

```

## 12. Optimizaciones adicionales

```bash
# Configurar lÃ­mites de memoria GPU (opcional)
export OLLAMA_GPU_MEMORY_FRACTION=0.8

# Configurar nÃºmero de capas en GPU
export OLLAMA_NUM_GPU_LAYERS=35

# Verificar configuraciÃ³n
env | grep OLLAMA

```

## 13. Comandos de mantenimiento

```bash
# Actualizar drivers NVIDIA
sudo apt update && sudo apt upgrade nvidia-driver-*

# Verificar temperatura GPU
nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits

# Monitorear uso en tiempo real
nvidia-smi dmon

```

---

# ğŸ“¦ InstalaciÃ³n del Proyecto CV Processor

## 1. Instalar dependencias del sistema

```bash
# Instalar Python y pip
sudo apt update
sudo apt install python3 python3-pip python3-venv

# Instalar dependencias del sistema para PDF
sudo apt install python3-dev build-essential
```

## 2. Clonar y configurar el proyecto

```bash
# Clonar el repositorio (ajustar segÃºn tu repositorio)
git clone <tu-repositorio>
cd cv-processor

# Crear entorno virtual
python3 -m venv .env
source .env/bin/activate

# Instalar dependencias Python
pip install -r requirements.txt
```

## 3. Configurar Ollama y descargar modelo

```bash
# Descargar el modelo DeepSeek-R1 (requerido por el sistema)
ollama pull deepseek-r1:1.5b

# Verificar que el modelo estÃ¡ disponible
ollama list
```

## 4. Preparar estructura de directorios

```bash
# Crear directorio para CVs
mkdir -p cvs

# Crear directorio para estÃ¡ticos (ya deberÃ­a existir)
mkdir -p static
```

## 5. Inicializar base de datos

```bash
# Ejecutar script de inicializaciÃ³n
python db.py
```

---

# ğŸš€ Uso del Sistema

## OpciÃ³n 1: Interfaz Web

```bash
# Iniciar servidor web
python api.py

# O con uvicorn
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

**Acceder a**: `http://localhost:8000`

### Funciones disponibles en la interfaz web:
- âœ… Upload de archivos PDF
- âœ… Listar CVs en el sistema
- âœ… Procesar todos los CVs automÃ¡ticamente
- âœ… Ver resultados de anÃ¡lisis
- âœ… GestiÃ³n de base de datos

## OpciÃ³n 2: LÃ­nea de Comandos

```bash
# Procesar todos los CVs en la carpeta 'cvs'
python main.py

# Se solicitarÃ¡ rol especÃ­fico (opcional)
```

## OpciÃ³n 3: API REST

### Endpoints disponibles:

**GET** `/` - PÃ¡gina principal
**GET** `/api` - Estado de la API
**POST** `/process-cvs` - Procesar todos los CVs
**GET** `/candidates` - Obtener candidatos procesados
**GET** `/pdf-files` - Listar archivos PDF
**POST** `/pdf-files` - Subir nuevo PDF
**DELETE** `/pdf-files/{filename}` - Eliminar PDF
**DELETE** `/database` - Limpiar base de datos

### Ejemplo de uso con curl:

```bash
# Procesar CVs
curl -X POST "http://localhost:8000/process-cvs" \
     -H "Content-Type: application/json" \
     -d '{"role": "desarrollador"}'

# Obtener candidatos
curl -X GET "http://localhost:8000/candidates"
```

---

# ğŸ“ Estructura del Proyecto

```
cv-processor/
â”œâ”€â”€ README.md                 # Este archivo
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”œâ”€â”€ main.py                  # Procesamiento por lotes
â”œâ”€â”€ api.py                   # Servidor FastAPI
â”œâ”€â”€ analysis.py              # LÃ³gica de anÃ¡lisis con IA
â”œâ”€â”€ models.py                # Modelos de base de datos
â”œâ”€â”€ db.py                    # InicializaciÃ³n de BD
â”œâ”€â”€ utils.py                 # Utilidades (extracciÃ³n PDF)
â”œâ”€â”€ view_db.py              # Visualizador de BD
â”œâ”€â”€ index.html              # Interfaz web principal
â”œâ”€â”€ candidates.db           # Base de datos SQLite
â”œâ”€â”€ static/                 # Recursos web
â”‚   â”œâ”€â”€ style.css           # Estilos
â”‚   â””â”€â”€ script.js           # JavaScript
â”œâ”€â”€ cvs/                    # Directorio para CVs
â”‚   â””â”€â”€ *.pdf               # Archivos PDF a procesar
â””â”€â”€ .env/                   # Entorno virtual Python
```

---

# ğŸ”§ ConfiguraciÃ³n Avanzada

## Variables de Entorno para GPU

El sistema estÃ¡ optimizado para aprovechar al mÃ¡ximo las GPUs NVIDIA:

```bash
# En analysis.py se configuran automÃ¡ticamente:
export OLLAMA_GPU=1
export OLLAMA_GPU_LAYERS=35
export OLLAMA_VRAM_FRACTION=0.8
export CUDA_VISIBLE_DEVICES=0
export NVIDIA_VISIBLE_DEVICES=0
export OLLAMA_CUDA=1
export OLLAMA_DEBUG=1
```

## ConfiguraciÃ³n del Modelo IA

En `analysis.py`, puedes ajustar:

```python
MODEL_NAME = "deepseek-r1:1.5b"  # Modelo utilizado
MAX_RETRIES = 2                  # Reintentos en caso de error
```

## PersonalizaciÃ³n de AnÃ¡lisis

El sistema permite personalizar:
- **ExtracciÃ³n de habilidades**: Lista whitelist en `extract_skills_from_text()`
- **Ãreas profesionales**: CategorÃ­as en `extract_professional_area()`
- **Prompts de IA**: Template en `create_honest_prompt()`

---

# ğŸ” Monitoreo y DepuraciÃ³n

## Verificar uso de GPU

```bash
# Durante el procesamiento, monitorear GPU
watch -n 1 nvidia-smi

# El sistema mostrarÃ¡ automÃ¡ticamente:
# âœ… GPU ACEPTADA: XXXX MB libres
# ğŸš€ EJECUTANDO CON GPU FORZADA...
# âœ… CONFIRMADO: Ollama utilizÃ³ GPU durante la ejecuciÃ³n
```

## Logs del sistema

```bash
# Ver logs de Ollama
journalctl -u ollama -f

# Ver procesos GPU activos
nvidia-smi pmon

# Monitorear temperatura y uso
nvidia-smi dmon
```

## Troubleshooting ComÃºn

### âŒ Error: GPU no disponible
```bash
# Verificar drivers
nvidia-smi

# Reiniciar servicio Ollama
sudo systemctl restart ollama

# Verificar variables de entorno
env | grep CUDA
env | grep OLLAMA
```

### âŒ Error: Modelo no encontrado
```bash
# Descargar modelo requerido
ollama pull deepseek-r1:1.5b

# Verificar modelos disponibles
ollama list
```

### âŒ Error: PDF no se puede procesar
```bash
# Verificar permisos del directorio cvs/
ls -la cvs/

# Verificar que el PDF no estÃ© corrupto
file cvs/tu-archivo.pdf
```

---

# ğŸ“Š MÃ©tricas y Rendimiento

## Rendimiento esperado (con GPU NVIDIA GTX 1050):
- **Tiempo por CV**: 15-45 segundos
- **Memoria GPU utilizada**: ~1.5-2GB
- **PrecisiÃ³n de extracciÃ³n**: 85-95%
- **Formatos soportados**: PDF (texto extraÃ­ble)

## Monitoreo de mÃ©tricas:
- El sistema incluye timestamps de procesamiento
- VerificaciÃ³n automÃ¡tica de uso de GPU
- Logging detallado de errores y excepciones

---

# ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:

1. Fork del repositorio
2. Crear branch para feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

---

# ğŸ› ï¸ Notas TÃ©cnicas Importantes

## Compatibilidad GPU
1. **Requerimientos mÃ­nimos**: GTX 600 series o superior
2. **Memoria recomendada**: Para modelos grandes (7B+) necesitas al menos 8GB de VRAM
3. **Compatibilidad de versiones**: MantÃ©n consistencia entre driver NVIDIA, CUDA toolkit y Ollama
4. **Reinicio obligatorio**: DespuÃ©s de instalar drivers, siempre reinicia el sistema

## VerificaciÃ³n Final de InstalaciÃ³n

Si todo estÃ¡ configurado correctamente, cuando ejecutes el anÃ¡lisis de CVs deberÃ­as ver:

- âœ… GPU utilizada en `nvidia-smi`
- âœ… Respuestas mÃ¡s rÃ¡pidas del modelo de IA
- âœ… Uso de VRAM en lugar de RAM del sistema
- âœ… Logs confirmando "CONFIRMADO: Ollama utilizÃ³ GPU durante la ejecuciÃ³n"

## Seguridad y Privacidad

- âš ï¸ Los CVs se procesan localmente (no se envÃ­an a servidores externos)
- âš ï¸ Los datos se almacenan en SQLite local
- âš ï¸ Se recomienda configurar backups regulares de la BD
- âš ï¸ Implementar autenticaciÃ³n para uso en producciÃ³n

---

# ğŸ“ Soporte

Para reportar problemas o solicitar funcionalidades:
- Crear issue en el repositorio
- Incluir logs relevantes y especificaciones del sistema
- Describir pasos para reproducir el problema

**Â¡El sistema estÃ¡ optimizado para aprovechar al mÃ¡ximo la aceleraciÃ³n GPU y proporcionar anÃ¡lisis precisos de CVs en espaÃ±ol!**# Proyecto_IEEE
